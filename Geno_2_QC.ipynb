{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44199acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import dxdy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830c5dd",
   "metadata": {},
   "source": [
    "## QC process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download command\n",
    "def dx_download(project_name, file_name, dest_name):\n",
    "    quoted_path = f'\"{project_name}:{file_name}\"'\n",
    "    download_command = f\"dx download {quoted_path} -o {dest_name}\"\n",
    "    print(f\"Downloading {file_name} from {project_name} to {dest_name}\")\n",
    "    subprocess.run(download_command, shell=True, check=True)\n",
    "\n",
    "# upload command\n",
    "def dx_upload(file_name, dest_name):\n",
    "    upload_command = f\"dx upload {file_name} -o {dest_name}\"\n",
    "    print(f\"Uploading {file_name} to {dest_name}\")\n",
    "    subprocess.run(upload_command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2fb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download genotype data from DNA Nexus\n",
    "# make and check dirctory\n",
    "saving_dir = \"UKB62k_genotype_data\"\n",
    "if not os.path.exists(saving_dir):\n",
    "    os.makedirs(saving_dir)\n",
    "    \n",
    "    \n",
    "# project_id = dxpy.api.user_get_project({'project': dxpy.DXProject('').get_id()})['project']\n",
    "# project_name = dxpy.DXProject(project_id).describe()['name']\n",
    "project_name = \"project-GxqpVq0Jpp5Py82xVbZV198y\"\n",
    "\n",
    "# cloud genotype data path\n",
    "genotype_origin_folder = \"/GWAS_pipeline/Genotype_data\"\n",
    "\n",
    "\n",
    "# file_list\n",
    "chr_num_list = list(range(1, 23))\n",
    "chr_num_list = list(map(str, chr_num_list))\n",
    "chr_num_list.append('X')\n",
    "chr_num_list.append('XY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c84e1",
   "metadata": {},
   "source": [
    "## Download all chromosomes plink files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all chromosomes\n",
    "for i in chr_num_list:\n",
    "    file_name = f\"chr{i}_62k.bed\"\n",
    "    dest_name = f\"{saving_dir}/chr{i}_62k.bed\"\n",
    "    dx_download(project_name, genotype_origin_folder + \"/\" + file_name, dest_name)\n",
    "    file_name = f\"chr{i}_62k.bim\"\n",
    "    dest_name = f\"{saving_dir}/chr{i}_62k.bim\"\n",
    "    dx_download(project_name, genotype_origin_folder + \"/\" + file_name, dest_name)\n",
    "    file_name = f\"chr{i}_62k.fam\"\n",
    "    dest_name = f\"{saving_dir}/chr{i}_62k.fam\"\n",
    "    dx_download(project_name, genotype_origin_folder + \"/\" + file_name, dest_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a2e8f",
   "metadata": {},
   "source": [
    "## Create merge list for plink merge test and remove triallelic SNPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c935427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create merge_list for plink merge\n",
    "with open(\"merge_list.txt\", \"w\") as f:\n",
    "    for i in range(2, 22):\n",
    "        f.write(f\"{saving_dir}/chr{i}_62k\\n\")\n",
    "        \n",
    "\n",
    "command = f\"plink --bfile {saving_dir}/chr1_62k --merge-list merge_list.txt --out {saving_dir}/test_merge\"\n",
    "try:\n",
    "    subprocess.run(command,shell=True,check=True)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"!Merge failed â€” expected during SNP cleanup.\")\n",
    "    print(f\"Return code: {e.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93972dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove triallelic SNPs and create cleaned files\n",
    "def clean_chromosomes(base_path, missnp_file, output_suffix=\"_cleaned\"):\n",
    "    for chr in range(1, 23):#chr 1-22\n",
    "        prefix = f\"{base_path}/chr{chr}_62k\"\n",
    "        output = f\"{prefix}{output_suffix}\"\n",
    "        \n",
    "        cmd = f\"plink --bfile {prefix} --exclude {missnp_file} --make-bed --out {output}\"\n",
    "        \n",
    "        print(f\"Running PLINK cleaning for chr{chr}...\")\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "        print(f\"chr cleaned: {output}\")\n",
    "        \n",
    "clean_chromosomes(saving_dir, saving_dir+\"/test_merge.missnp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate merge_list_cleaned for plink merge\n",
    "with open(\"merge_list_cleaned.txt\", \"w\") as f:\n",
    "    for i in range(2, 22):\n",
    "        f.write(f\"{saving_dir}/chr{i}_62k_cleaned\\n\")\n",
    "        \n",
    "\n",
    "# Combine all plink files to one autosome file: file name is ukb62k_autosome\n",
    "command = f\"plink --bfile {saving_dir}/chr1_62k_cleaned --merge-list merge_list_cleaned.txt --make-bed --out {saving_dir}/ukb62k_autosome\"\n",
    "subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946fd6e",
   "metadata": {},
   "source": [
    "## QC starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample QC function\n",
    "def sample_qc(input_file, output_file, mind, geno, hwe):\n",
    "    print(f\"Performing sample QC on {input_file}...\")\n",
    "    cmd = f\"plink2 --bfile {input_file} \\\n",
    "                --mind {mind} \\\n",
    "                --geno {geno} \\\n",
    "                --hwe {hwe} \\\n",
    "                --make-bed \\\n",
    "                --out {output_file}\"\n",
    "    print(cmd)\n",
    "    subprocess.run(cmd, shell=True, check=True)\n",
    "    \n",
    "    \n",
    "# Sample QC\n",
    "input_file = f\"{saving_dir}/ukb62k_autosome\"\n",
    "output_file = f\"{saving_dir}/ukb62k_autosome_qc\"\n",
    "mind = 0.1\n",
    "geno = 0.05\n",
    "hwe = 1e-6\n",
    "sample_qc(input_file, output_file, mind, geno, hwe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload QCed ukb62k_autosome\n",
    "dx_upload(f\"{saving_dir}/ukb62k_autosome_qc.bed\", f\"{genotype_origin_folder}/ukb62k_autosome_qc.bed\")\n",
    "dx_upload(f\"{saving_dir}/ukb62k_autosome_qc.bim\", f\"{genotype_origin_folder}/ukb62k_autosome_qc.bim\")\n",
    "dx_upload(f\"{saving_dir}/ukb62k_autosome_qc.fam\", f\"{genotype_origin_folder}/ukb62k_autosome_qc.fam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece30b90",
   "metadata": {},
   "source": [
    "## Subset and filter subjects (to be updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset and filter sample file create (to be updated)\n",
    "#Filter csv file\n",
    "def subset_samples(input_file, output_file, filter_caucasian: bool = True):\n",
    "    print(f\"Subsetting samples from {input_file} to {output_file}...\")\n",
    "    # Load CSV and standardize column names\n",
    "    df = pd.read_csv(input_file, sep=\",\")\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    # Filter by Caucasian\n",
    "    if filter_caucasian:\n",
    "        df = df[df[\"p22006\"] == \"1\"]\n",
    "    else:\n",
    "        print(\"No filtering applied for Caucasian samples.\")\n",
    "    \n",
    "    # format for plink keep\n",
    "    keep_df = df[[\"eid\"]].rename(columns={\"eid\": \"IID\"})\n",
    "    keep_df = keep_df.assign(FID=keep_df[\"IID\"])[[\"FID\", \"IID\"]]\n",
    "    \n",
    "    # Save to file\n",
    "    keep_df.to_csv(output_file, sep=\"\\t\", index=False, header=False)\n",
    "    print(f\"Saved {len(keep_df)} samples to {output_file}\")\n",
    "    \n",
    "    \n",
    "# Filter participant for plink\n",
    "def filter_participant(input_file, output_file, keep_file):\n",
    "    print(f\"Performing filtering on {input_file}...\")\n",
    "    cmd = f\"plink2 --bfile {input_file} \\\n",
    "            --keep {keep_file} \\\n",
    "            --make-bed \\\n",
    "            --out {output_file}\"\n",
    "    print(cmd)\n",
    "    subprocess.run(cmd, shell=True, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf94450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Caucasian individuals\n",
    "# make and check dirctory\n",
    "\n",
    "# Subset samples: initial file has already prepared from the cohort app\n",
    "dx_download(project_name, \"full_participant.csv\", \"participant_table.csv\")\n",
    "\n",
    "if not os.path.exists(f\"{saving_dir}/ukb62k_autosome_qced\"):\n",
    "    os.makedirs(f\"{saving_dir}/ukb62k_autosome_qced\")\n",
    "    \n",
    "\n",
    "# Filter the participant table\n",
    "subset_samples(\"participant_table.csv\", f\"{saving_dir}/ukb62k_autosome_qced/keep.txt\", filter_caucasian=True)\n",
    "\n",
    "# Filter the genotype data\n",
    "filter_participant(f\"{saving_dir}/ukb62k_autosome_qced\", f\"{saving_dir}/ukb54k_EUR_qced\", f\"{saving_dir}/ukb62k_autosome_qced/keep.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de313dee",
   "metadata": {},
   "source": [
    "## Create GRM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cedf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LD_pruned SNP list\n",
    "dx_download(project_name, f\"{genotype_origin_folder}/hapmap3.prune.in\", \"UKB_genotype_data/hapmap3.prune.in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97501c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse GRM\n",
    "print(\"Creating sparse GRM...\")\n",
    "if os.path.exists(f\"{saving_dir}/GRM/ukb62k_autosome_qced_sparse.grm.bin\"):\n",
    "    print(\"Sparse GRM already exists. Skipping creation.\")\n",
    "else:\n",
    "    os.makedirs(f\"{saving_dir}/GRM\", exist_ok=True)\n",
    "\n",
    "# Create GRM function\n",
    "def grm_create(input_file, output_file, extract_snp_file, thread=10, sparse_cutoff=0.05):\n",
    "    print(f\"Creating GRM for {input_file}...\")\n",
    "    cmd = f\"gcta64 --bfile {input_file} \\\n",
    "                --autosome \\\n",
    "                --extract {extract_snp_file} \\\n",
    "                --make-grm \\\n",
    "                --thread-num {thread} \\\n",
    "                --sparse-cutoff {sparse_cutoff} \\\n",
    "                --out {output_file}\"\n",
    "    print(cmd)\n",
    "    subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GRM\n",
    "grm_create(f\"{saving_dir}/ukb54k_EUR_qced\", f\"{saving_dir}/GRM/ukb54k_EUR_qced_sprs_grm\", \"hapmap3.prune.in\", thread=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload GRM files to DNA Nexus\n",
    "print(\"Uploading GRM files to DNA Nexus...\")\n",
    "dx_upload(f\"{saving_dir}/GRM/ukb54k_EUR_qced_sprs_grm.grm.id\", f\"{genotype_origin_folder}/GRM/ukb54k_EUR_qced_sprs_grm.grm.id\")\n",
    "dx_upload(f\"{saving_dir}/GRM/ukb54k_EUR_qced_sprs_grm.grm.sp\", f\"{genotype_origin_folder}/GRM/ukb54k_EUR_qced_sprs_grm.grm.sp\")\n",
    "dx_upload(f\"{saving_dir}/GRM/ukb54k_EUR_qced_sprs_grm.log\", f\"{genotype_origin_folder}/GRM/ukb54k_EUR_qced_sprs_grm.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424001b6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
